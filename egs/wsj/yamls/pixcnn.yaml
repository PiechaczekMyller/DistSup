Datasets:
  train:
    class_name: FixedDatasetLoader
    batch_size: 32
    dataset:
      class_name: distsup.data.ChunkedDataset
      dataset:
        class_name: egs.wsj.data.WSJData
        split: train_si284
        text_fname: text_phn
        vocab_fname: vocabulary_phn.txt
        split_by_space: true
        ali_file: text_ali
        cmvn_normalize_var: true
      chunk_len: 64
      training: true
      varlen_fields: [features, alignment]
      drop_fields: [targets, text, alignment_rle]
    rename_dict: {features: image}
    shuffle: true
    num_workers: 6
  dev:
    class_name: FixedDatasetLoader
    batch_size: 32
    dataset:
      class_name: distsup.data.ChunkedDataset
      dataset:
        class_name: egs.wsj.data.WSJData
        split: test_dev93
        text_fname: text_phn
        vocab_fname: vocabulary_phn.txt
        split_by_space: true
        ali_file: text_ali
        cmvn_normalize_var: true
      chunk_len: 64
      training: true
      varlen_fields: [features, alignment]
      drop_fields: [targets, text, alignment_rle]
    rename_dict: {features: image}
    shuffle: true
    num_workers: 6

Model:
  class_name: distsup.models.generators_autoregressive.Autoregressive2D
  condition_on_alignment: true
  num_alignment_classes: 45
  image_height: 81
  reconstructor:
    class_name: distsup.modules.reconstructors.ColumnGatedPixelCNN
    reconstruction_channel: 0
    quantizer:
      class_name: distsup.modules.quantizers.SoftmaxQuantizer
      levels: [-1.9530852 , -1.7284005 , -1.5876112 , -1.4978249 , -1.4173771 ,
              -1.339192  , -1.2740152 , -1.2111483 , -1.1495873 , -1.0888968 ,
              -1.0342782 , -0.9816667 , -0.93131596, -0.8768976 , -0.82089734,
              -0.7643442 , -0.7053138 , -0.6469244 , -0.58405584, -0.52547514,
              -0.45990476, -0.39368019, -0.3199903 , -0.24699803, -0.18008633,
              -0.11815459, -0.05262136,  0.01312537,  0.07447001,  0.1358178 ,
                0.19516519,  0.25697222,  0.3113174 ,  0.37070978,  0.4314164 ,
                0.49065787,  0.56037414,  0.6332032 ,  0.7052329 ,  0.77813464,
                0.843494  ,  0.90251267,  0.9609936 ,  1.0317255 ,  1.101294  ,
                1.1816055 ,  1.2701552 ,  1.343959  ,  1.4179286 ,  1.490372  ,
                1.5696365 ,  1.6645858 ,  1.7577237 ,  1.8494363 ,  1.9660066 ,
                2.1031072 ,  2.2526898 ,  2.4071977 ,  2.594809  ,  2.76624   ,
                2.917514  ,  3.1646917 ,  3.5152757 ,  3.855438  ]

Trainer:
  checkpointer:
    every_n_hours: 4
  gradient_clipping:
    clip_norm: 20.0
  learning_rate: 0.001
  learning_rate_scheduler:
    class_name: torch.optim.lr_scheduler.ReduceLROnPlateau
    factor: 0.5
    patience: 2
  output_frequency: 1
  num_epochs: 101
  optimizer_name: Adam
  polyak_decay:
  - 0.9998
