Datasets:
  train:
    class_name: FixedDatasetLoader
    batch_size: 32
    dataset:
      class_name: egs.mnist.Dataset
      train: True
    shuffle: true
    num_workers: 2
  dev:
    class_name: FixedDatasetLoader
    batch_size: 32
    dataset:
      class_name: egs.mnist.Dataset
      train: False
    num_workers: 2

Model:
  class_name: distsup.models.simple.MLP
  num_classes: 10
  num_inputs: [28, 28]
  hidden_dims: [2000, 1000]

Trainer:
  checkpointer:
    every_n_hours: 4
  gradient_clipping:
    clip_norm: 10.0
  learning_rate: 0.001
  learning_rate_scheduler:
    class_name: torch.optim.lr_scheduler.ReduceLROnPlateau
    factor: 0.5
    patience: 2
  output_frequency: 100
  num_epochs: 50
  optimizer_name: Adam
  optimizer_kwargs:
    betas: [0.9, 0.999]
  weight_noise: 0.05
  weight_noise_start_iteration: 10000
  polyak_decay:
  - 0.9998
